[{"content":"回忆录 一句话：我搞砸了一切！\n在2025年里面我没有了她，想哭，却哭不出来。\n每当刷到《我的婚礼》时候，里面有句话让我印象深刻，或许那就是想哭的原因吧。“如果我能早点长大，是不是就不会失去你了”，如果我能早点长大，是不是就能看到你的委屈，如果我能早点长大，是不是更好的照顾你。\n我不后悔遇到她，我不后悔我给她全部，我不后悔！\n是她让我感受到什么是喜欢，什么是恋爱！\n在这个期间里面，我尝试过咨询心理老师，我希望走出那个困境，我希望我自己能够做的更好，可是我没有，可是。哪有那么多可是啊！\n我们…\n好难受啊，我总是回忆起和她之间发生的美好，我的情绪起起伏伏，我不知道去如何解决这些，有很多建议，可是我真的提不起来兴趣，甚至我有种冲动，想找她复合，但是这是不好的，可能不是理性的，我害怕我会重复之前的模式，更加的卑微。我真的给了全部啊，我现在什么都没有了，我不怪她，她对我有很多失望，我想起来很多事情，总是会有一个假设，那就是”如果我可以做的更好“，但是不可能了，现在我终于听懂了《轨迹》这首歌，我听明白了，现在的状态真的和这首歌一样。\n我的头好疼啊，越来越难受了，不知道未来的几个星期我应该如何度过，不知道应该做什么？\n我在这一段感情中，明白了很多事情，我弄丢了自己，也弄丢了她。\n好难受，真的好难受啊！！！看着那天我们说的话，我觉得或许真的不合适吧！！！\n期望 希望在新的一年里面，我可以好好去面对自己，好好的去对待自己。\n目标 减到130斤并保持 拿到实习offer 拿到理想的工作 ","date":"2024-12-31T00:00:00Z","permalink":"https://www.yangdiy.cn/p/2024/","title":"2024回忆与展望"},{"content":"\n数据结构 1. Redis的数据类型以及实现的原理 Redis 中5 种基础数据类型：String（字符串）、List（列表）、Set（集合）、Hash（散列）、Zset（有序集合）。\n又支持了四种数据类型： BitMap（2.2 版新增）、HyperLogLog（2.8 版新增）、GEO（3.2 版新增）、Stream（5.0 版新增）。\n这些数据结构均为值的底层实现方式，在 Redis 中，核心在于键与值之间的组织。只要理解了这一核心要点，那么对于其他数据结构的操作，其实就是先找到值，然后在集合中进行相关操作。\nRedis 使用了一个哈希表来保存所有键值对，一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。哈希表的每一项是一个 dictEntry 的结构体，dictEntry 结构中有三个 8 字节的指针，分别指向 key、value 以及下一个 dictEntry，三个指针共 24 字节。值保存的并不是值本身，而是指向具体值的指针。\nRedis 会用一个 RedisObject 结构体来统一记录各个数据类型的元数据，同时指向实际数据。一个 RedisObject 包含了 8 字节的元数据和一个 8 字节指针。\n2. 哈希表存在的冲突问题 当你往哈希表中写入更多数据时，可能两个 key 的哈希值和哈希桶计算对应关系时，正好落在了同一个哈希桶中。这就是哈希表存在的冲突问题。\nRedis 解决哈希冲突的方式，就是链式哈希，就是指同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。\n3. 为什么需要rehash？ 哈希冲突链上的元素只能通过指针逐一查找再操作。如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低。\n所以需要rehash操作，也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。\n4. rehash是怎么做的，rehash会带来什么问题？怎么解决？ Redis 默认有两个全局哈希表：哈希表 1 和哈希表 2。开始插入数据时用哈希表 1，此时哈希表 2 未分配空间。数据增多时执行 rehash，分三步：\n给哈希表 2 分配更大空间，如哈希表 1 的两倍； 把哈希表 1 数据重新映射并拷贝到哈希表 2； 释放哈希表 1 空间，然后切换到哈希表 2 保存更多数据，哈希表 1 留作下次 rehash 扩容备用。 （就是把数据向另一个更大的表拷贝了一下，之后就是两个表相互这样倒腾。）\n存在一个问题：如果一次性把哈希表 1 中的数据都迁移完，会造成 Redis 线程阻塞，无法服务其他请求。此时，Redis 就无法快速访问数据了。\n解决这个问题，采用渐进式 rehash。\n在第二步拷贝数据时，Redis 正常处理客户端请求。每处理一个请求，就从哈希表 1 的第一个索引位置开始，顺带把此索引位置的所有 entries 拷贝到哈希表 2 。处理下一个请求时，再顺带拷贝哈希表 1 下一个索引位置的 entries。\n渐进式 rehash巧妙地把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操作，保证了数据的快速访问。\n如果有新的请求进来，在rehash过程中：\n对于查询、删除、更新等操作，Redis 会先在当前正在使用的哈希表（一般称为旧表）中进行查找。如果没有找到，再到正在 rehash 的新哈希表中查找。\n对于插入操作，如果当前正在 rehash，新元素可能会被插入到新哈希表中，以加快 rehash 的完成。\n5. 整数数组和压缩列表在查找时间复杂度方面并没有很大的优势，那为什么 Redis 还会把它们作为底层数据结构呢？ 整数数组和压缩列表在存储相对紧凑的数据时，能够更有效地利用内存空间。相比于一些更复杂的数据结构，它们减少了内存开销和内存碎片的产生。 在数据量较小且操作相对简单的场景下，整数数组和压缩列表的实现较为简单，操作的性能开销相对较低，可以更好地利用 CPU 的缓存机制，提高数据访问的效率。 即使当进行随机访问时，虽然不是顺序访问，但由于数组元素的内存地址相邻，第一次访问某个元素可能未命中高速缓存，但相邻元素被加载进高速缓存的概率较大。 string 内部实现 String 类型的底层的数据结构实现主要是 int 和 SDS（简单动态字符串）。\n简单动态字符串（Simple Dynamic String，SDS）结构体，如下：\nbuf：字节数组，保存实际数据。为了表示字节数组的结束，Redis 会自动在数组最后加一个“\\0”，这就会额外占用 1 个字节的开销。\nlen：占 4 个字节，表示 buf 的已用长度。\nalloc：也占个 4 字节，表示 buf 的实际分配长度，一般大于 len。\n分配方式：\n当保存的是 Long 类型整数时，RedisObject 中的指针就直接赋值为整数数据了，这样就不用额外的指针再指向整数了，节省了指针的空间开销。 embstr 编码方式：当保存的是字符串数据，并且字符串小于等于 44 字节时，RedisObject 中的元数据、指针和 SDS 是一块连续的内存区域，这样就可以避免内存碎片。 raw 编码：当字符串大于 44 字节时，SDS 的数据量就开始变多了，Redis 就不再把 SDS 和 RedisObject 布局在一起了，而是会给 SDS 分配独立的空间，并用指针指向 SDS 结构。 embstr 与 raw 编码优缺点：\nembstr编码将创建字符串对象所需的内存分配次数从 raw 编码的两次降低为一次； 释放 embstr编码的字符串对象同样只需要调用一次内存释放函数； 因为embstr编码的字符串对象的所有数据都保存在一块连续的内存里面可以更好的利用 CPU 缓存提升性能。 embstr编码的字符串对象实际上是只读的，redis没有为embstr编码的字符串对象编写任何相应的修改程序。当我们对embstr编码的字符串对象执行任何修改命令（例如append）时，程序会先将对象的编码从embstr转换成raw，然后再执行修改命令。 应用场景 缓存对象 分布式锁 共享 Session 信息 List BitMap Bitmap，即位图，是一串连续的二进制数组（0和1），可以通过偏移量（offset）定位元素。BitMap通过最小的单位bit来进行0|1的设置，表示某个元素的值或者状态，时间复杂度为O(1)。\n内部实现 Bitmap 本身是用 动态字符串 (SDS, Simple Dynamic String) 作为底层数据结构实现的一种统计二值状态的数据类型。\nRedis 将其存储为普通的字符串对象，但允许对其进行位操作，可以把 Bitmap 看作是一个 bit 数组。\n应用场景 Bitmap 类型非常适合二值状态统计的场景，这里的二值状态就是指集合元素的取值就只有 0 和 1 两种，在记录海量数据时，Bitmap 能够有效地节省内存空间。\n签到统计 判断用户登录态 一个 key = login_status 表示存储用户登陆状态集合数据， 将用户 ID 作为 offset，在线就设置为 1，下线设置 0。 连续签到用户总数 提供了 BITOP operation destkey key [key ...]这个指令用于对一个或者多个 key 的 Bitmap 进行位元操作。 HyperLogLog HyperLogLog 是是一种用于「统计基数」的数据集合类型，基数统计就是指统计一个集合中不重复的元素个数。但要注意，HyperLogLog 是统计规则是基于概率完成的，不是非常准确，标准误算率是 0.81%。\nHyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的内存空间总是固定的、并且是很小的。\n在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。\n应用场景 统计百万级以上的网页 UV 的场景 GEO GEO 主要用于存储地理位置信息，并对存储的信息进行操作。\n内部实现 GEO 本身并没有设计新的底层数据结构，而是直接使用了 Sorted Set 集合类型。\nGEO 类型使用 GeoHash 编码方法实现了经纬度到 Sorted Set 中元素权重分数的转换，这其中的两个关键机制就是「二分区间」和「区间编码」。\n当我们要对一组经纬度进行 GeoHash 编码时，我们要先对经度和纬度分别编码，然后再把经纬度各自的编码组合成一个最终编码。\n具体编码过程：\nGeoHash 编码会把一个经度值编码成一个 N 位的二进制，具体是对经度范围[-180,180]做 N 次的二分区操作，其中 N 可以自定义，你落在哪个分区，该位置上取0/1. 纬度同上 最终编码值的偶数位上依次是经度的编码值，奇数位上依次是纬度的编码值，其中，偶数位从 0 开始，奇数位从 1 开始。 可以理解成「对二维地图进行区间划分」，「对区间进行编码」，经纬度落在哪个区间，那就是对应的二进制值。\n应用场景 LBS （Location-Based Service）应用访问的数据是和人或物关联的一组经纬度信息，而且要能查询相邻的经纬度范围，GEO 就非常适合应用在 LBS 服务的场景中。\n线程模型 1. redis 为什么是单线程的？ 增加线程数，系统吞吐率会增加，但是，再进一步增加线程时，系统吞吐率就增长迟缓了，有时甚至还会出现下降的情况。\n2. 单线程的redis 为什么这么快呢？ Redis 的大部分操作在内存上完成，再加上它采用了高效的数据结构。\n采用单线程模型可以避免了多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。\nRedis 采用了多路复用机制，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。\n3. 基本IO模型会存在什么问题？ 存在阻塞问题：\n以一个Get请求为例，需要监听客户端请求（bind/listen），和客户端建立连接（accept），从 socket 中读取请求（recv），解析客户端发送请求（parse），根据请求类型读取键值数据（get），最后给客户端返回结果（send）。\n这个六个过程有潜在的阻塞点，分别是 accept() 和 recv()。\n当 Redis 监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在 accept() 函数这里，导致其他客户端无法和 Redis 建立连接。当 Redis 通过 recv() 从一个客户端读取数据时，如果数据一直没有到达，Redis 也会一直阻塞在 recv()。\n存在大量线程创建导致资源浪费：\n每个用户请求到来都得占用一个进程来处理，来一个请求就要分配一个进程跟进处理，显然在高并发的情况下会导致资源的浪费\n4. 什么是多路复用 在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理。\n当被监听的套接字准备执行连接应答（accept）、读取（read）、写入（write）、关 闭（close）等操作时，与操作相对应的文件事件就会产生，这些事件会被放进一个事件队列，不同事件会调用相应的处理函数，这就实现了基于事件的回调。\n5. 在Redis IO 模型，还有哪些潜在的性能瓶颈吗？ 任意一个请求在server中一旦发生耗时，都会影响整个server的性能，也就是说后面的请求都要等前面这个耗时请求处理完成，自己才能被处理到。耗时的操作包括以下几种： 操作bigkey：写入一个bigkey在分配内存时需要消耗更多的时间，同样，删除bigkey释放内存同样会产生耗时； 使用复杂度过高的命令：例如SORT/SUNION/ZUNIONSTORE，或者O(N)命令，但是N很大，例如lrange key 0 -1一次查询全量数据； 大量key集中过期：Redis的过期机制也是在主线程中执行的，大量key集中过期会导致处理一个请求时，耗时都在删除过期key，耗时变长； 淘汰策略：淘汰策略也是在主线程执行的，当内存超过Redis内存上限后，每次写入都需要淘汰一些key，也会造成耗时变长； AOF刷盘开启always机制：每次写入都需要把这个操作刷到磁盘，写磁盘的速度远比写内存慢，会拖慢Redis的性能； 主从全量同步生成RDB：虽然采用fork子进程生成数据快照，但fork这一瞬间也是会阻塞整个线程的，实例越大，阻塞时间越久； 并发量非常大时，单线程读写客户端IO数据存在性能瓶颈，虽然采用IO多路复用机制，但是读写客户端数据依旧是同步IO，只能单线程依次读取客户端的数据，无法利用到CPU多核。 针对问题1，一方面需要业务人员去规避，一方面Redis在4.0推出了lazy-free机制，把bigkey释放内存的耗时操作放在了异步线程中执行，降低对主线程的影响。\n针对问题2，Redis在6.0推出了多线程，可以在高并发场景下利用CPU多核多线程读写客户端数据，进一步提升server性能，当然，只是针对客户端的读写是并行的，每个命令的真正操作依旧是单线程的。\n为什么redis6.0后引入多线程 Redis 采用单线程设计的原因：\n基于内存操作，多数操作性能瓶颈非 CPU 导致。 单线程模型代码简便，可减少线程上下文切换的性能开销。 单线程结合 I/O 多路复用模型能提高 I/O 利用率。 Redis 6.0 版本引入多线程的原因：随着数据规模和请求量增加，执行瓶颈主要在网络 I/O，引入多线程可提高网络 I/O 处理速度。\n存储 1. Redis是如何实现持久化？ Redis 共有三种数据持久化的方式：\nAOF 日志：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里； RDB 快照：将某一时刻的内存数据，以二进制的方式写入磁盘； 混合持久化方式：Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点； 2. AOF有什么优点以及有什么风险 避免额外的检查开销：因为如果先将写操作命令记录到 AOF 日志里，再执行该命令的话，如果当前的命令语法有问题，那么如果不进行命令语法检查，该错误的命令记录到 AOF 日志里后，Redis 在使用日志恢复数据时，就可能会出错。 不会阻塞当前写操作命令的执行：因为当写操作命令执行成功后，才会将命令记录到 AOF 日志。 当然，这样做也会带来风险：\n数据可能会丢失： 执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有丢失的风险。 可能阻塞其他操作： 由于写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前命令的执行，但因为 AOF 日志也是在主线程中执行，所以当 Redis 把日志文件写入磁盘的时候，还是会阻塞后续的操作无法执行。 3. AOF 写回策略 AOF 风险与AOF回写磁盘是有关的，控制一个写命令执行完后 AOF 日志写回磁盘的时机，风险就会解除。\n三种策略：\nAlways，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；\nEverysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；\nNo，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。\n总结：想要获得高性能，就选择 No 策略；如果想要得到高可靠性保证，就选择 Always 策略；如果允许数据有一点丢失，又希望性能别受太大影响的话，那么就选择 Everysec 策略。\n4. 日志文件太大怎么办？ AOF 文件过大带来的性能问题，主要在于以下三个方面：\n文件系统本身对文件大小有限制，无法保存过大的文件； 如果文件太大，之后再往里面追加命令记录的话，效率也会变低； 如果发生宕机，AOF 中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢，这就会影响到 Redis 的正常使用。 Redis 为了避免 AOF 文件越写越大，提供了 AOF 重写机制，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。\n重写的流程：根据这个键值对当前的最新状态，为它生成对应的写入命令。相当于旧日志文件中的多条命令，在重写后的新日志中变成了一条命令。\n你也可以理解成redis最新状态的保存\n5. AOF重写会阻塞吗？ 一个拷贝，两处日志\nAOF重写会通过 fork 创建一个子进程 bgrewriteaof，由子进程完成重写工作，不阻塞主线程处理请求，保障了服务的高可用性。\n主线程 fork 出一个子进程进行 AOF 重写操作，子进程独立完成新 AOF 文件的生成，避免主线程阻塞。 子进程基于拷贝的数据，逐步将操作记录写入新的 AOF 文件。 主线程不会因为 AOF 重写而阻塞，能够继续处理读写请求。 新的写操作会先写入现有的 AOF 文件，以确保数据持久性。 同时，这些写操作也会被记录到子进程的重写缓冲区中，以保证新的 AOF 文件包含最新的操作。 重写完成后，新的 AOF 文件替代旧文件。 6. AOF 日志重写的时候，是由 bgrewriteaof 子进程来完成的，不用主线程参与，这个重写过程有没有其他潜在的阻塞风险呢？如果有的话，会在哪里阻塞？ 风险一：Redis 主线程 fork 创建 bgrewriteaof 子进程时，内核需要创建用于管理子进程的相关数据结构，这些数据结构在操作系统中通常叫作进程控制块（Process Control Block，简称为 PCB）。内核要把主线程的 PCB 内容拷贝给子进程。这个创建和拷贝过程由内核执行，是会阻塞主线程的。而且，在拷贝过程中，子进程要拷贝父进程的页表，这个过程的耗时和 Redis 实例的内存大小有关。如果 Redis 实例内存大，页表就会大，fork 执行时间就会长，这就会给主线程带来阻塞风险。\n风险二：bgrewriteaof 子进程会和主线程共享内存。当主线程收到新写或修改的操作时，主线程会申请新的内存空间，用来保存新写或修改的数据，如果操作的是 bigkey，也就是数据量大的集合类型数据，那么，主线程会因为申请大空间而面临阻塞风险。因为操作系统在分配内存空间时，有查找和锁的开销，这就会导致阻塞。\n7. AOF 重写也有一个重写日志，为什么它不共享使用 AOF 本身的日志呢？ 竞争问题 保证一致性和安全性 8. 什么是内存快照，对哪些数据做内存快照？ 用 AOF 方法进行故障恢复的时候，需要逐一把操作日志都执行一遍。如果操作日志非常多，Redis 就会恢复得很缓慢，影响到正常使用。所以需要另一种持久化方法：内存快照。就是指内存中的数据在某一个时刻的状态记录。\n为了提供所有数据的可靠性保证，它执行的是全量快照，也就是说，把内存中的所有数据都记录到磁盘中。\nRedis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave。\nsave：在主线程中执行，会导致阻塞；\nbgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。\n9. 做快照时，数据还能被增删改吗，是否会发生阻塞？ Redis 就会借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。\n具体过程是：bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。如果主线程对这些数据也都是读操作，那么，主线程和 bgsave 子进程相互不影响。如果主线程要修改一块数据那么，这块数据就会被复制一份，生成该数据的副本。然后，主线程在这个数据副本上进行修改。同时，bgsave 子进程可以继续把原来的数据写入 RDB 文件。\n写时复制优缺点：\n优点：减少不必要的资源分配，节省宝贵的物理内存。\n缺点：如果在子进程存在期间发生了大量写操作，那么会频繁地产生页面错误，不断陷入内核，复制页面。这反而会降低效率。\n10. 执行快照的间隔时间如何选择？ 快照的间隔时间变得很短，即使某一时刻发生宕机了，因为上一时刻快照刚执行，丢失的数据也不会太多。 但是频繁将全量数据写入磁盘，会给磁盘带来很大压力，同时bgsave 子进程需要通过 fork 操作从主线程创建出来。fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。 基于此很难将间隔时间选择的很好。\n11. 有什么方法既能利用 RDB 的快速恢复，又能以较小的开销做到尽量少丢数据呢 Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。\n快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。\nRedis 中的内存碎片化是什么？如何进行优化？ Redis 的内存碎片化是指内存使用中出现小块空间被闲置，无法被有效利用的现象。\n如何形成：\n内因：Redis 默认使用 jemalloc 作为内存分配器，它是按照固定大小来分配内存的，比如实际需要 8kb 的内存，分配器给了 12kb。\n外因：频繁创建和删除大量数据的时候，会导致内存块大小和位置不连续，内存碎片会变多。\n可以通过 INFO memory 命令查看内存碎片率(mem_fragmentation_ratio)：\nmem_fragmentation_ratio = used_memory_rss / used_memory，所以大于 1 就代表有内存碎片。大于1.5需要降低内存碎片率了。\n如何解决内存碎片：\n最简单的解决方法是定期重启 Redis 服务，这样可以消除内存碎片并优化内存的布局，但是会导致服务不可用。 Redis 4.0 及以上版本引入了内存碎片整理功能。通过配置 activedefrag 选项，Redis 可以在运行时尝试整理内存碎片，将小的内存块合并为更大的块。 通过优化数据存储结构和类型。如：使用 ListPack 替代 ziplist。 利用 MEMORY PURGE 命令手动清理碎片，但是这个命令会阻塞主线程。 高可用 1. 主从复制如何保证高可用？ Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离的方式。\n读操作：主库、从库都可以接收；\n写操作：首先到主库执行，然后，主库将写操作同步给从库，使得主从库的数据是一致的。\n2. 主从库间的第一次同步是如何进行的 第一阶段是主从库间建立连接、协商同步的过程，主要是为全量复制做准备。 从库给主库发送 psync 命令，表示要进行数据同步，psync 命令包含了主库的 runID 和复制进度 offset 两个参数。 主库收到 psync 命令后，会用 FULLRESYNC 响应命令带上两个参数：主库 runID 和主库目前的复制进度 offset。 在第二阶段，主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载。 主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。 在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作。 第三个阶段将刚才执行过程中新收到的写命令，再发送给从库。 之后主从之间会维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为基于长连接的命令传播，可以避免频繁建立连接的开销。\n3. 如何分担全量复制的主库压力 如果从库数量很多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。此外，传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。\n通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上。\n具体来说：在部署主从集群的时候，可以手动选择一个从库（比如选择内存资源配置较高的从库），用于级联其他的从库。\n4. 网路断连了，从库恢复后怎么保证一致性？ 网络断了之后，主从库会采用增量复制的方式继续同步。增量复制只会把主从库网络断连期间主库收到的命令，同步给从库。\n具体而言：当主从库断连后，主库会把断连期间收到的写操作命令，写入 repl_backlog_buffer 这个缓冲区。repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。对主库来说，对应的偏移量就是 master_repl_offset。主库接收的新写操作越多，这个值就会越大。当从库复制完命令后，从库已复制的偏移量 slave_repl_offset 也在不断增加。\n主从库的连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断自己的 master_repl_offset 和 slave_repl_offset 之间的差距。主库只用把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库就行。\n存在的问题：因为 repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。\n为了避免该问题，将缓冲空间调大。\n5. 为什么主从库间的复制不使用 AOF 呢？ AOF文件记录的是每一次写操作的命令，写操作越多文件会变得很大，其中还包括很多对同一个key的多次冗余操作。RDB文件内容是经过压缩的二进制数据（不同数据类型数据做了针对性优化），文件很小。\n从库在加载文件时候，读取RDB文件速度较快，AOF需要依次重放每个写命令，这个过程会经历冗长的处理逻辑，恢复速度相比RDB会慢得多。\n6.如果主库挂了，应该怎么办？ 依赖哨兵（Sentinel）机制，哨兵其实就是一个运行在特殊模式下的 Redis 进程，它的作用是实现主从节点故障转移。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。\n7.哨兵机制，如何判断主从库处于下线状态 主观下线：哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。如果哨兵发现主库或从库对 PING 命令的响应超时了，那么，哨兵就会先把它标记为“主观下线”。\n客观下线：当有 N 个哨兵实例时，最好要有 N/2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。\n对从库标记为主观下线，一般影响不大，集群的对外服务不会间断，但是对于主库则不能简单的标记为主观下线，因为有可能「主节点」其实并没有故障，可能只是因为主节点的系统压力比较大或者网络发送了拥塞，导致主节点没有在规定时间内响应哨兵的 PING 命令，同时哨兵误判了，其实主库并没有故障。可是，一旦启动了主从切换，后续的选主和通知操作都会带来额外的计算和通信开销。\n为了减少误判的情况，则对主库采用客观下线，用多个节点部署成哨兵集群（最少需要三台机器来部署哨兵集群），通过多个哨兵节点一起判断，就可以就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。\n8. 哨兵机制，如何选择从库作为主库 在多个从库中，先按照一定的筛选条件，把不符合条件的从库去掉。然后，再按照一定的规则，给剩下的从库逐个打分，将得分最高的从库选为新主库，\n筛选条件：\n要检查从库的当前在线状态，还要判断它之前的网络连接状态。\n如果在 down-after-milliseconds 毫秒（主从断连的最大连接超时时间）内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了。如果发生断连的次数超过了 10 次，就说明这个从库的网络状况不好，不适合作为新主库。\n打分规则：\n分别是从库优先级、从库复制进度以及从库 ID 号。\n第一轮：优先级最高的从库得分高。\n用户可以通过 slave-priority 配置项，给不同的从库设置不同优先级。例如根据内存大小设置不一样的优先级。\n第二轮：和旧主库同步程度最接近的从库得分高。\n如果在所有从库中，有从库的 slave_repl_offset 最接近 master_repl_offset，那么它的得分就最高，可以作为新主库。\n第三轮：ID 号小的从库得分高。\n在优先级和复制进度都相同的情况下，ID 号最小的从库得分最高，会被选为新主库。\n总结：首先，哨兵会按照在线状态、网络状态，筛选过滤掉一部分不符合要求的从库，然后，依次按照优先级、复制进度、ID 号大小再对剩余的从库进行打分，只要有得分最高的从库出现，就把它选为新主库。\n9. 哨兵集群是如何组成的，如何与主从库建立连接？ 哨兵实例之间可以相互发现，主要依赖于 Redis 提供的 pub/sub 机制，也就是发布 / 订阅机制。\n哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信息（IP 和端口）。同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端口。\n在主从集群中，主库上有一个名为“sentinel:hello”的频道，不同哨兵就是通过它来相互发现，实现互相通信的。\n与从库的连接，是由哨兵向主库发送 INFO 命令来完成的，主库接受到这个命令后，就会把从库列表返回给哨兵。接着，哨兵就可以根据从库列表中的连接信息，和每个从库建立连接，并在这个连接上持续地对从库进行监控。\n10. 有哪个哨兵来作为领导者，执行主从切换？ 选举 leader 的过程其实是一个投票的过程，哪个哨兵节点判断主节点为「客观下线」，这个哨兵节点就是候选者。候选者会向其他哨兵发送命令，表明希望成为 Leader 来执行主从切换，并让所有其他哨兵对它进行投票。\n每个哨兵只有一次投票机会，如果用完后就不能参与投票了，可以投给自己或投给别人，但是只有候选者才能把票投给自己。\n那么在投票过程中，任何一个「候选者」，要满足两个条件：\n第一，拿到半数以上的赞成票； 第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。 11. Redis 1 主 4 从，5 个哨兵 ，quorum 设置为 2，如果 3 个哨兵故障，当主节点宕机时，哨兵能否判断主节点“客观下线”？主从能否自动切换？ 哨兵集群可以判定主库“主观下线”。由于quorum=2，所以当一个哨兵判断主库“主观下线”后，询问另外一个哨兵后也会得到同样的结果，2个哨兵都判定“主观下线”，达到了quorum的值，因此，哨兵集群可以判定主库为“客观下线”。 但哨兵不能完成主从切换。哨兵标记主库“客观下线后”，在选举“哨兵领导者”时，一个哨兵必须拿到超过多数的选票(5/2+1=3票)。但目前只有2个哨兵活着，无论怎么投票，一个哨兵最多只能拿到2票，永远无法达到多数选票的结果。 12. 如果要用 Redis 保存 5000 万个键值对，每个键值对大约是 512B，会有什么问题？怎么解决？ 为了保存大量数据，会采用两种方法：\n纵向扩展：升级单个 Redis 实例的资源配置，包括增加内存容量、增加磁盘容量、使用更高配置的 CPU。\n横向扩展：横向增加当前 Redis 实例的个数，就是采用切片集群，也叫分片集群，就是指启动多个 Redis 实例组成一个集群，然后按照一定的规则，把收到的数据划分成多份，每一份用一个实例来保存。\n纵向扩展的好处是，实施起来简单、直接。\n存在两个问题：\n在使用 RDB 进行持久化时，Redis 会 fork 子进程来完成，fork 操作的用时和 Redis 的数据量是正相关的，而 fork 在执行时会阻塞主线程。数据量越大，fork 操作造成的主线程阻塞的时间越长。 纵向扩展会受到硬件和成本的限制。 13.数据切片，多个实例如何分布？ Redis Cluster 方案采用哈希槽（Hash Slot），来处理数据和节点之间的映射关系。在 Redis Cluster 方案中，一个切片集群共有 16384 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中，具体执行过程分为两大步：\n根据键值对的 key，按照 CRC16 算法 (opens new window)计算一个 16 bit 的值。 再用 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。 至于哈希槽如何被映射到对应的实例中，一般有两种方案：\n平均分配： 在使用 cluster create 命令创建 Redis 集群时，Redis 会自动把所有哈希槽平均分布到集群节点上。比如集群中有 9 个节点，则每个节点上槽的个数为 16384/9 个。 手动分配： 可以使用 cluster meet 命令手动建立节点间的连接，组成集群，再使用 cluster addslots 命令，指定每个节点上的哈希槽个数。 注意：在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。\n14. 客户端怎么准确找到那个访问数据的对应的实例？ Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。\n15.如果哈希槽与实例的对应关系发生了变化，又如何找到？ 最常见的变化有两个：\n在集群中，实例有新增或删除，Redis 需要重新分配哈希槽； 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。 Redis Cluster 方案提供了一种**重定向机制，**所谓的“重定向”，就是指，客户端给一个原实例发送数据读写操作时，这个实例上并没有相应的数据，这个实例就会给客户端返回MOVED 命令包含新实例的访问地址，客户端要再给一个新实例发送操作命令。\n16. 假设在迁移的过程中，某个哈希槽迁移了部分数据，这时候客户端访问会发生什么？ 在这种迁移部分完成的情况下，客户端就会收到一条 ASK 报错信息， ASK 命令就表示，客户端请求的键值对所在的哈希槽在新的实例上，但是这个哈希槽正在迁移。此时，客户端需要先给新的实例发送一个 ASKING 命令。这个命令的意思是，让这个实例允许执行客户端接下来发送的命令。然后，客户端再向这个实例发送 GET 命令，以读取数据。\n注意：ASK 命令并不会更新客户端缓存的哈希槽分配信息。\n17. 为什么 Redis 不直接用一个表，把键值对和实例的对应关系记录下来？ 表存储空间大：整个集群存储key的数量是无法预估的，key的数量非常多时，直接记录每个key对应的实例映射关系，这个映射表会非常庞大。 维护表成本高：当集群在扩容、缩容、数据均衡时，节点之间会发生数据迁移，迁移时需要修改每个key的映射关系，维护成本高。如果是单线程操作表，那么所有操作都要串行执行，性能慢；如果是多线程操作表，就涉及到加锁开销。 哈希槽可以把数据和节点解耦，key通过Hash计算，只需要关心映射到了哪个哈希槽，然后再通过哈希槽和节点的映射表找到节点，相当于消耗了很少的CPU资源，不但让数据分布更均匀，还可以让这个映射表变得很小，利于客户端和服务端保存，节点之间交换信息时也变得轻量。\nredis会出现脑裂的问题吗？如何去解决？ 脑裂，就是指在主从集群中，同时有两个主节点，它们都能接收写请求。客户端不知道应该往哪个主节点写入数据，结果就是不同的客户端会往不同的主节点上写入数据，脑裂会可能导致数据丢失和数据不一致。\n发生的原因：主库是由于某些原因无法处理请求，也没有响应哨兵的心跳，才被哨兵错误地判断为客观下线的。结果，在被判断下线之后，原主库又重新开始处理请求了，而此时，哨兵还没有完成主从切换，客户端仍然可以和原主库通信，客户端发送的写操作就会在原主库上写入数据了，同时从库升级成主库，就出现脑裂的情况。\n造成数据丢失原因：\n主从切换后哨兵就会让原主库执行 slave of 命令，和新主库重新进行全量同步。原主库需要清空本地的数据，加载新主库发送的 RDB 文件，这样一来，原主库在主从切换期间保存的新写数据就丢失了。 解决方案：\nmin-slaves-to-write：这个配置项设置了主库能进行数据同步的最少从库数量；\nmin-slaves-max-lag：这个配置项设置了主从库间进行数据复制时，从库给主库发送 ACK 消息的最大延迟（以秒为单位）。\n举个例子：当 min-slaves-to-write 设置为 2，min-slaves-max-lag 设置为 10 秒时，主节点只有在至少有 2 个从节点延迟不超过 10 秒的情况下才会接受写操作。\n功能 如何保存时间序列数据 时间序列数据特点：\n写：插入数据快 读：对单条记录的查询以及对某个时间范围内的数据的查询，同时对某个时间范围内的数据做聚合计算等等。 方案一：Hash 和 Sorted Set 组合\n关于 Hash 类型，可以实现对单键的快速查询，可以把时间戳作为 Hash 集合的 key，把记录的设备状态值作为 Hash 集合的 value。\n**Hash 类型有个短板：它并不支持对数据进行范围查询。**为了能同时支持按时间戳范围的查询，可以用 Sorted Set 来保存时间序列数据，因为它能够根据元素的权重分数来排序。我们可以把时间戳作为 Sorted Set 集合的元素分数，把时间点上记录的数据作为元素本身。\n存在问题：\nmember重复问题 Sorted Set 只支持范围查询，无法直接进行聚合计算，所以，我们只能先把时间范围内的数据取回到客户端，然后在客户端自行完成聚合计算。导致大量数据在 Redis 实例和客户端间频繁传输，这会和其他操作命令竞争网络资源，导致其他操作变慢。 所有的数据会在两个数据类型中各保存一份，内存开销高。 方案二：RedisTimeSeries\nRedisTimeSeries 是 Redis 的一个扩展模块。它专门面向时间序列数据提供了数据类型和访问接口，并且支持在 Redis 实例上直接对数据进行按时间范围的聚合计算。\n优缺点：\nRedisTimeSeries 能支持直接在 Redis 实例上进行多种数据聚合计算，避免了大量数据在实例和客户端间传输。 不过，RedisTimeSeries 的底层数据结构使用了链表，它的范围查询的复杂度是 O(N) 级别的。 它的 TS.GET 查询只能返回最新的数据，没有办法像第一种方案的 Hash 类型一样，可以返回任一时间点的数据。 利用redis如何做消息队列 消息队列在存取消息时，必须要满足三个需求，分别是消息保序、处理重复的消息和保证消息可靠性。\n基于List的消息队列解决方案\n消息保序：生产者可以使用 LPUSH 命令把要发送的消息依次写入 List，而消费者则可以使用 BRPOP 命令，从 List 的另一端按照消息的写入顺序，依次读取消息并进行处理。BRPOP 命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据。\n去重：用 LPUSH 命令把消息插入 List 时，需要在消息中包含这个全局唯一 ID。\n保证可靠性：List 类型提供了 BRPOPLPUSH 命令，这个命令的作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List（可以叫作备份 List）留存。消费者程序读了消息但没能正常处理，等它重启后，就可以从备份 List 中重新读取消息并进行处理了。\n存在的问题：**List 类型并不支持消费组的实现：**生产者消息发送很快，而消费者处理消息的速度比较慢，这就导致 List 中的消息越积越多，给 Redis 的内存带来很大压力。\n基于 Streams 的消息队列解决方案\nStreams 是 Redis 专门为消息队列设计的数据类型，它提供了丰富的消息队列操作命令。\nXADD：插入消息，保证有序，可以自动生成全局唯一 ID；\nXREAD：用于读取消息，可以按 ID 读取数据；\nXREADGROUP：按消费组形式读取消息；\nXPENDING：XPENDING 命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息\nXACK：XACK 命令用于向消息队列确认消息处理已完成。\nRedis缓存的淘汰策略 Redis 内存淘汰策略共有八种，这八种策略大体分为「不进行数据淘汰」和「进行数据淘汰」两类策略。\n不进行数据淘汰策略 noeviction（Redis3.0之后，默认） ：它表示当运行内存超过最大设置内存时，不淘汰任何数据，这时如果有新的数据写入，会报错通知禁止写入，不淘汰任何数据。\n进行数据淘汰策略 在设置了过期时间的数据中进行淘汰：\nvolatile-random：随机淘汰设置了过期时间的任意键值； volatile-ttl：优先淘汰更早过期的键值。 volatile-lru（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值； volatile-lfu（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值； 在所有数据范围内进行淘汰：\nallkeys-random：随机淘汰任意键值; allkeys-lru：淘汰整个键值中最久未使用的键值； allkeys-lfu（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。 LRU算法 LRU 全称是 Least Recently Used 翻译为最近最少使用，会选择淘汰最近最少使用的数据。\n传统 LRU 算法的实现是基于「链表」结构，链表中的元素按照操作顺序从前往后排列，最新操作的键会被移动到表头，当需要内存淘汰时，只需要删除链表尾部的元素即可，因为链表尾部的元素就代表最久未被使用的元素。\n存在问题：\n需要用链表管理所有的缓存数据，这会带来额外的空间开销； 当有数据被访问时，需要在链表上把该数据移动到头端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。 Redis 实现的是一种近似 LRU 算法，目的是为了更好的节约内存，它的实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间。Redis 在决定淘汰的数据时，根据数据范围会随机选出 N 个数据，把它们作为一个候选集合。然后淘汰最久没有使用的那个。\nRedis 实现的 LRU 算法的优点：\n不用为所有的数据维护一个大链表，节省了空间占用； 不用在每次数据访问时都移动链表项，提升了缓存的性能； 但是 LRU 算法有一个问题，无法解决缓存污染问题，比如应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间，造成缓存污染。\nLFU LFU 全称是 Least Frequently Used 翻译为最近最不常用，LFU 算法是根据数据访问次数来淘汰数据的，它的核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。\n在 LFU 算法中，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，低 8bit 存储 logc(Logistic Counter)。\nLFU 策略设计使用非线性增长的计数器来表示数据的访问次数，为了避开 8bit 最大只能记录 255 的限制。如果counter值越大，递增概率越低\n设计了一个 logc(Logistic Counter)值的衰减机制:对于当前时间与上一次访问的时间差距（分钟为单位）乘以一个衰减速度(lfu-decay-time)，得到衰减值。默认值为1，lfu-decay-time 值越大，衰减越慢；\nRedis缓存的过期删除策略 设置过期时间：\nexpire \u0026lt;key\u0026gt; \u0026lt;n\u0026gt;：设置 key 在 n 秒后过期，比如 expire key 100 表示设置 key 在 100 秒后过期； pexpire \u0026lt;key\u0026gt; \u0026lt;n\u0026gt;：设置 key 在 n 毫秒后过期，比如 pexpire key2 100000 表示设置 key2 在 100000 毫秒（100 秒）后过期。 expireat \u0026lt;key\u0026gt; \u0026lt;n\u0026gt;：设置 key 在某个时间戳（精确到秒）之后过期，比如 expireat key3 1655654400 表示 key3 在时间戳 1655654400 后过期（精确到秒）； pexpireat \u0026lt;key\u0026gt; \u0026lt;n\u0026gt;：设置 key 在某个时间戳（精确到毫秒）之后过期，比如 pexpireat key4 1655654400000 表示 key4 在时间戳 1655654400000 后过期（精确到毫秒） 定时删除策略的做法是，在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作。\n优点：可以保证过期key尽快被删除；\n缺点：容易在极端情况，造成cpu紧张；\n惰性删除策略的做法是，不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。\n优点：对cpu友好；\n缺点：容易造成一定的空间浪费；\n定期删除策略的做法是，每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。\n优点：折中；\n缺点：需要控制删除操作时长和频率；\nRedis 选择「惰性删除+定期删除」这两种策略配和使用，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。\n具体实现：\n详细说说 Redis 的定期删除的流程：\n在 Redis 中，默认每秒进行 10 次过期检查一次数据库 从过期字典中随机抽取 20 个 key； 检查这 20 个 key 是否过期，并删除已过期的 key； 如果本轮检查的已过期 key 的数量，超过 5 个（20/4），也就是「已过期 key 的数量」占比「随机抽取 key 的数量」大于 25%，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查。 分布式锁的实现 基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满足三个条件。\n加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁，实现「key不存在才插入」； 锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX/PX 选项，设置其过期时间； 锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端； 1 SET lock_key unique_value NX PX 10000 lock_key 就是 key 键； unique_value 是客户端生成的唯一的标识，区分来自不同客户端的锁操作； NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作； PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁。 对于解锁：\n解锁的过程就是将 lock_key 键删除（del lock_key），但不能乱删，要保证执行操作的客户端就是加锁的客户端。所以，解锁的时候，要先判断锁的 unique_value 是否为加锁客户端，是的话，才将 lock_key 键删除。这个过程需要 Lua 脚本来保证解锁的原子性；\n优缺点：\n具有性能高效、实现简单等优点。 超时时间不好设置。设置过短，保护不了共享资源（例如业务没有执行完）。 解决方案：租约机制。写一个守护线程，然后去判断锁的情况，当锁快失效的时候，再次进行续约加锁，当主线程执行完成后，销毁续约锁即可。 Redis在主从模型下，分布式锁不可靠。**Redis 主从复制模式中的数据是异步复制的，**在 Redis 主节点获取到锁后，在没有同步到其他节点时，Redis 主节点宕机了，此时新的 Redis 主节点依然可以获取锁。 为了保证集群环境下分布式锁的可靠性，Redis 官方已经设计了一个分布式锁算法 Redlock（红锁）。\nRedlock 算法的基本思路，是让客户端和多个独立的 Redis 节点依次请求申请加锁，如果客户端能够和半数以上的节点成功地完成加锁操作并且总耗时没有超过锁的有效时间，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败。\nRedlock 算法加锁三个过程：\n第一步是，客户端获取当前时间（t1）。 第二步是，客户端按顺序依次向 N 个 Redis 节点执行加锁操作： 加锁操作使用 SET 命令，带上 NX，EX/PX 选项，以及带上客户端的唯一标识。 如果某个 Redis 节点发生故障了，为了保证在这种情况下，Redlock 算法能够继续运行，我们需要给「加锁操作」设置一个超时时间（不是对「锁」设置超时时间，而是对**「加锁操作」设置超时时间**），加锁操作的超时时间需要远远地小于锁的过期时间，一般也就是设置为几十毫秒。 第三步是，一旦客户端从超过半数（大于等于 N/2+1）的 Redis 节点上成功获取到了锁，就再次获取当前时间（t2），然后计算计算整个加锁过程的总耗时（t2-t1）。如果 t2-t1 \u0026lt; 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败。 如何实现事务机制 Redis 支持事务，通过使用 MULTI、EXEC、WATCH 和 DISCARD 等命令来实现。事务中的命令会被排队并在调用 EXEC 时一次性执行，保证了事务的原子性。\n具体实现流程如下：\n开始事务：使用 MULTI 命令开始一个事务，之后的所有命令都会被排队。 添加命令：在事务中添加命令，这些命令不会立即执行，而是存储在队列中。 执行事务：使用 EXEC 命令执行队列中的所有命令，确保原子性。 取消事务：使用 DISCARD 命令可以放弃事务，清空命令队列。 监视键：使用 WATCH 命令可以监视一个或多个键，如果在事务执行前这些键被修改，则 EXEC 将不会执行，确保数据一致性。 注意：redis不支持事务运行时错误的事务回滚。\n秒杀场景，redis做了什么 秒杀场景的负载特征对支撑系统的要求：\n第一个特征是瞬时并发访问量非常高。 第二个特征是读多写少，而且读操作是简单的查询操作。 第一阶段是秒杀活动前：用户会不断刷新商品详情页，这会导致详情页的瞬时请求量剧增。这个阶段的应对方案，一般是尽量把商品详情页的页面元素静态化，然后使用 CDN 或是浏览器把这些静态化的元素缓存起来。\n第二阶段是秒杀活动开始。这个阶段的操作就是三个：库存查验、库存扣减和订单处理。当库存查验完成后，一旦库存有余量，我们就立即在 Redis 中扣减库存。然后在数据库中进行订单处理。核心在于：在库存查验、库存扣减操作中，在redis中保证原子性。\n在这一个阶段，还可以使用redis分布式锁来支撑。\n第三阶段就是秒杀活动结束后。这个阶段中的用户请求量已经下降很多了，服务器端一般都能支撑。\n缓存 缓存一致性如何发生以及解决 缓存和数据库的同步可以通过以下几种方式:\n先更新缓存，再更新数据库\n先更新数据库存，再更新缓存\n以上两种会因为并发问题导致数据不一致。当两个请求并发更新同一条数据的时候，可能会出现缓存和数据库中的数据不一致的现象。\n一般的解决方法：\n加锁：在更新缓存前先加个分布式锁，保证同一时间只运行一个请求更新缓存，就会不会产生并发问题了。 在更新完缓存时，给缓存加上较短的过期时间，不一致出现的时间较短，业务可以接受。（勉强的方案） 先删除缓存，再更新数据库，后续等查询把数据库的数据回种到缓存中 先更新数据库，再删除缓存，后续等查询把数据库的数据回种到缓存中 延迟双删：更新数据库之前，删除一次缓存；更新完数据库后，再进行一次延迟删除；也只是尽可能保证一致性而已，极端情况下，依然也会出现缓存不一致的现象。\n对于解决存在操作失败的可能的解决方案：\n重试机制：引入消息队列，将第二个操作要操作的数据加入到消息队列，由消费者来操作数据。\n如果应用删除缓存失败，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是重试机制。当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。 如果删除缓存成功，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。 订阅 MySQL binlog，再操作缓存：将binlog日志采集发送到MQ队列里面，然后编写一个简单的缓存删除消息者订阅binlog日志，根据更新log删除缓存，并且通过ACK机制确认处理这条更新log，保证数据缓存一致性。这里有一个很关键的点，必须是删除缓存成功，再回 ack 机制给消息队列，否则可能会造成消息丢失的问题，所以会加上重试机制。\n以上是方案是尽可能保证缓存和数据库具有一定的一致性。如果希望强一致性：加分布式锁，串行化。\n缓存异常 雪崩 缓存雪崩是指当大量缓存数据在同一时间过期（失效）或者 Redis 故障宕机时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃。\n针对大量数据同时过期而引起的问题，解决方案：\n微调过期时间： 在对缓存数据设置过期时间时，给这些数据的过期时间加上一个随机数，这样就保证数据不会在同一时间过期。\n服务降级： 当业务应用访问的是非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息；\n当业务应用访问的是核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。\n使用多级缓存：引入多级缓存机制，如本地缓存和分布式缓存相结合，减少单点故障风险。 加互斥锁：使得没缓存或缓存失效的情况下，同一时间只有一个请求来构建缓存，防止数据库压力过大。 针对Redis宕机引起的问题，解决方案：\n服务熔断或请求限流机制： 启动服务熔断机制，暂停业务应用对缓存服务的访问，直接返回错误，不用再继续访问数据库，从而降低对数据库的访问压力，会带来业务无法正常工作问题。\n为了减少对业务的影响，我们可以启用请求限流机制，只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务，等到 Redis 恢复正常并把缓存预热完后，再解除请求限流的机制。\n构建 Redis 缓存高可靠集群：通过主从节点的方式构建 Redis 缓存高可靠集群。 击穿 击穿：如果缓存中的某个热点数据过期了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮。\n解决方案：\n热点数据永不过期：不给热点数据设置过期时间，由后台异步更新缓存。 加互斥锁：使得没缓存或缓存失效的情况下，保证同一时间只有一个请求来构建缓存。 穿透 穿透是指当用户访问的数据，既不在缓存中，也不在数据库中，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增。\n解决方案：\n防止非法请求：检查非法请求，封禁其 IP 以及账号，防止它再次为非作歹。\n缓存空值：将数据库中不存在的结果（例如空值）也缓存起来，并设置一个较短的过期时间，避免频繁查询数据库。\n使用布隆过滤器：使用布隆过滤器来快速判断一个请求的数据是否存在，如果布隆过滤器判断数据不存在，则直接返回，避免查询数据库。\n","date":"2024-12-11T00:00:00Z","permalink":"https://www.yangdiy.cn/p/redis/","title":"Redis-八股题"},{"content":" 自己读剑来这个小说的感受，给我很大的启发。一些特别喜欢的句子都写在里面。\n自己觉得不好的事情，就干脆不要有第一次，一次也不要做，一小步也不能走出去，要不然回头来看，吃亏吃苦的还是自己。 一个随便把别人当朋友的人，往往不会有真正的朋友。一个喜欢嘴上称兄道弟的人，心里其实没有真正的兄弟。 请不要把陌生人的些许善意，视为珍稀的瑰宝，却把身边亲近人的全部付出，当做天经地义的事情，对其视而不见。 读过多少书，就敢说这个世道“就是这样的”，见过多少人，就敢说男人女人“都是这般德行”？你亲眼见过多少太平和苦难，就敢断言他人的善恶？ 少年的肩膀，就该这样才对嘛，什么家国仇恨，浩然正气的，都不要急，先挑起清风明月、杨柳依依和草长莺飞，少年郎的肩头，本就应当满是美好的事物啊。 是你的就好好抓住，不是你的就不要多想。天底下没谁是欠你的，但是你欠了别人，就别不当回事。 只是两个人相处，那么喜欢一个人，可能会觉得她所有都好，但是以后在一起了，就要学会喜欢她的不好。 别人的大道再好，那也是别人的道路，不妨埋头做事，但问耕耘莫问收获，偶尔抬头，左右看两眼其它路上的人物风光，就够了。 言念君子，温其如玉。 人生不是书上的故事，喜怒哀乐，悲欢离合，都在书页间，可书页翻篇何其易，人心修补何其难。 遇事不决，可问春风，春风不语，既随本心。可我若本心坚定，怎会遇事不决，春风也有春风愁，不劳春风为我忧。 岁岁平，岁岁安，岁岁平安，年年岁岁，岁岁年年，平平安安。 若是不喜欢，做这些，未必有用。是不是画蛇添足，就不重要。若是原本就有些喜欢，看了这些，说不定会更加喜欢。 世间道理，其实一直在，有人捡起，奉若圭臬，视为珍宝，有人不屑，甚至还有人会踩上几脚。 这不是道理不对，不好。 而是人心出了问题。 我是否喜欢谁，与谁喜不喜欢我，半颗铜钱关系都没有。就像山看水，水流山还在，喜欢之人，只管远去，我只管喜欢。 被人喜欢，是一件很难得、需要很珍惜的事情，比不被讨厌还要难嘛，所以可不是一件可以拿来炫耀的事情，就应该只是一件偷藏在心里的高兴事啊，然后偶尔心情不好的时候，一开门，就会高兴嘞，一开门就心情好，所以就叫‘开心’嘛。” 文字在有些时候，恰恰会是我们认识这个世界的无形障碍。所以你以后读书的时候，不要时时刻刻都去咬文嚼字，若是遇到了瓶颈，不妨先退一步，再登高数步，尽量往高处走一走，不登山峰，不显平地。 欲要从容，必先心定。 积少成多，聚沙成塔是好事，只是不要钻牛角尖，事事处处吹毛求疵，不然要么心性很难澄澈皎然，要么劳心劳力，虽然筋骨雄壮，却早已心神憔悴。 如何对他人给予善意，是一门大学问。不是“我觉得”三个字，就可以弥补所有因为好心办坏事带来的后果。 当这个世界给予自己善意的时候，一定要好好珍惜，要惜福，无论大小。 书上学理，书外做人。 我与你心平气和说话，不是你范大澈有多对，只是我有家教。 那些将威严放在脸上的剑修前辈，不需要怕，真正需要敬畏的，反而是那些平时很好说话的。因为所谓的性格棱角，不是漏进鞋子里的小石子，处处硌脚，让人每走一步都难受。而是那种溪涧里的鹅卵石，瞧着任人拿捏，但真要咬一嘴，就会真正磕牙。 “稳，还有一解，解为‘人不急’三字，其意与慢相近。只是慢却无错，最终求快，故而急。 情怀这东西，自然是不能当饭吃的，可没有情怀，就像炒菜没有佐料，每顿都是白饭加无味菜，久而久之，就真的没有嚼头了。有些味道，能够让你辣得满眼泪水，酸得牙齿直打颤，苦得肝胆欲破裂，大概这就是情怀。 有些远远的喜欢，总是忍不住要让人知道，才能甘心。 与亲近之人，不要说气话，不可说反话，尤其不要不说话。 无心犯错不可怕，有心改错即修行。 就像男女情爱之间的磕磕碰碰，其实女子那些让男子摸不着头脑的情绪，本身就是道理，认可她的这份情绪，再帮忙疏解情绪，等女子渐渐不在气头上了，然后再来与她心平气和说些自己道理，才是正途。这就叫退一步思量，先后顺序的学以致用，一旦跳过前边的那个环节，万事休矣。 ","date":"2024-12-07T00:00:00Z","permalink":"https://www.yangdiy.cn/p/jianlai/","title":"剑来语录"},{"content":"背包问题 参考 https://en.oi-wiki.org/dp/knapsack/ 【题单】https://huxulm.github.io/lc-rating/list/dynamic_programming https://www.bilibili.com/video/BV16Y411v7Y6/ ","date":"2024-11-30T17:11:59+08:00","permalink":"https://www.yangdiy.cn/p/knapsack/","title":"Knapsack"},{"content":"MySQL 基础架构 其实图相对重要一些，一些相关题目可以记忆这个图进行回答\nMysql分为Server层和存储引擎层两部分。\n连接器： 身份认证和权限相关 查询缓存： 执行查询语句的时候，会先查询缓存(命中概率低，8.0移除) 分析器： 进行词法分析和语法分析，检查是否正确以及进行鉴权 优化器： 决定选择使用最优方案，例如匹配索引，多表关联(join)的连接顺序 执行器： 执行语句，然后从存储引擎返回数据。 （会对实际运行的表进行鉴权） 插件式存储引擎：主要负责数据的存储和读取，支持 InnoDB、MyISAM、Memory 等多种存储引擎。 1. 查询语句在Mysql 的执行过程 1 select * from tb_student A where A.age=\u0026#39;18\u0026#39; and A.name=\u0026#39; 张三 \u0026#39;; 连接数据库 在 MySQL8.0 版本以前，会先查询缓存，以这条 SQL 语句为 key 在内存中查询是否有结果。（在工程实现中，在查询缓存返回结果之前，做权限校验）。 通过分析器进行词法分析，提取 SQL 语句的关键元素，比如提取上面这个语句是查询 select，提取需要查询的表名为 tb_student，需要查询所有的列，查询条件是这个表的 id=\u0026lsquo;1\u0026rsquo;。然后判断这个 SQL 语句是否有语法错误，比如关键词是否正确等等，如果检查没问题就执行下一步。（注：在词法分析阶段，会进行 precheck 验证权限，判断是否有权限。） 优化器进行确定执行方案，上面的 SQL 语句，可以有两种执行方案：a.先查询学生表中姓名为“张三”的学生，然后判断是否年龄是 18。b.先找出学生中年龄 18 岁的学生，然后再查询姓名为“张三”的学生。那么优化器根据自己的优化算法进行选择执行效率最好的一个方案（优化器认为，有时候不一定最好）。那么确认了执行计划后就准备开始执行了。 在执行器过程，会先进行权限校验，然后会调用数据库引擎接口，返回引擎的执行结果。 2. 更新语句在Mysql 的执行过程 1 update tb_student A set A.age=\u0026#39;19\u0026#39; where A.name=\u0026#39; 张三 \u0026#39;; 更新语句会沿着查询的流程走，与查询语句不同的是执行更新时候，会记录日志。\n执行器会找到目标行数据。如果目标行所在的数据页在内存（Buffer Pool ）中，就会直接返回执行器，否则需要从磁盘读入内存，再返回。 执行器拿到引擎给的行数据，修改对应字段值，得到新的一行数据，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。 5. 什么是数据页的空洞，如何解决？ 在InnoDB引擎中，删除某一行数据，会把这个一行数据标记为删除，表明可以复用。行数据的复用，只限于符合范围条件的数据。当你随机删除过多，会造成一个数据页中存在很多可以复用但是没有被使用的地方，称之为空洞。\n不止是删除数据会造成空洞，插入数据也会。\n当把一个数据页上的所有数据都删除，表明数据页也可以被复用，但是表空间不会回收。\n解决方案：使用Online DDL方式重建表\n重建表的流程：\n建立一个临时文件，扫描表 A 主键的所有数据页； 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中； 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中； 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件； 用临时文件替换表 A 的数据文件。 6. 在 select count(?) from t 这样的查询语句里面，count(*)、count(主键 id)、count(字段) 和 count(1) 等不同用法的性能，有哪些差别。 count(主键 id) ：InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。 count(1)：InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，往count函数放一个数字“1”进去，判断是不可能为空的，按行累加。 count(字段) ：【如果没有索引，走主键索引】 如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加； 如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。 count(*)：不需要取值，按行累加。【可能走最小的索引】 按照效率排序的话，count(字段)\u0026lt;count(主键id)\u0026lt;count(1) ≈ count(*)\n7.order by 中是如何排序的吗？ 有这样一个sql语句：\n1 select city,name,age from t where city=\u0026#39;杭州\u0026#39; order by name limit 1000 ; # city是索引 这个语句执行流程如下所示 ：\n初始化 sort_buffer，确定放入 name、city、age 这三个字段； 从索引 city 找到第一个满足 city=\u0026lsquo;杭州’条件的主键 id，也就是图中的 ID_X； 到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中； 从索引 city 取下一个记录的主键 id； 重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y； 对 sort_buffer 中的数据按照字段 name 做快速排序；按照排序结果取前 1000 行返回给客户端。、 MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer。\n也称之为全字段排序（把所需字段全放入 sort_buffer中）。\n对于 InnoDB 表来说，执行全字段排序会减少磁盘访问，因此会被优先选择。\n8. 全字段排序有什么性能限制吗？ 排序，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。\n排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则需要利用磁盘临时文件辅助排序。\n外部排序一般使用多路归并排序算法。\n如果查询要返回的字段很多的话，那么 sort_buffer 里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。\n9. 如何优化全字段排序带来的性能限制？ 增大 sort_buffer_size：尽量提高内存中的排序缓冲区大小，使得内存能够容纳更多的行，减少生成临时文件的数量。\n减少查询中返回的字段数量：查询时只返回必要的字段（使用 SELECT 时避免 SELECT *），减少单行数据占用的空间，从而让内存能够存储更多行。\n构建联合\\覆盖索引：让结果是有序的，减少排序过程。\n让Mysql 采用另一种排序方法：rowId 排序。\n10. rowid 排序是如何执行的？ max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。\n整个执行流程：\n初始化 sort_buffer，确定放入两个字段，即 name 和 id； 从索引 city 找到第一个满足 city=\u0026lsquo;杭州’条件的主键 id，也就是图中的 ID_X； 到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中； 从索引 city 取下一个记录的主键 id； 重复步骤 3、4 直到不满足 city=\u0026lsquo;杭州’条件为止，也就是图中的 ID_Y； 对 sort_buffer 中的数据按照字段 name 进行排序；遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。 与全字段排序的区别：\nsort_buffer 只放入和排序相关的字段 多了一次回表的过程，一般优化器会选择全字段排序。 如果 MySQL 认为排序内存太小，会采用 rowid 排序算法，如果 MySQL 认为内存足够大，会优先选择全字段排序。\n11.目前你返回的数据行数较多，如果返回行数较少，那么会使用什么排序？ 在 MySQL 中，排序会优先尝试使用内存：\n当需要排序的数据量小于 sort_buffer_size 时，MySQL 会将数据加载到内存中并直接进行排序（通常使用快速排序）； 如果数据量大于 sort_buffer_size，MySQL 会将数据分批加载到内存中，执行部分排序后写入临时文件，最后通过外部归并排序完成整体排序。 如果单行大于max_length_for_sort_data,Mysql将会使用rowid的排序。 对于 ORDER BY ... LIMIT N 的场景，MySQL 可能使用堆排序（优先队列）来优化性能，动态维护前 N 条记录，从而避免完全排序。 临时文件的使用则是基于内存不足时存储中间结果的需要。 12. order by rand() 是如何执行的？ 读取数据集：MySQL 从存储引擎中读取目标表中的所有符合条件的行（如果没有 WHERE 条件，则读取整个表）。 生成随机值：对于每一行，调用 RAND() 函数生成一个随机值，并将随机值与该行的数据关联存储在内存或临时表中。 排序：使用内存中的随机值作为排序键，对数据进行排序。如果数据量过大而无法全部放入内存，则使用磁盘上的临时文件进行外部排序。 返回结果：根据排序后的数据返回结果。如果指定了 LIMIT，则只返回前 N 条数据；否则返回排序后的所有行。 注意事项：\nORDER BY RAND() 对所有行生成随机数并排序，导致 CPU 和内存消耗较大。当表很大时，会严重影响性能。 优化建议：\n预先选取随机主键范围（如 WHERE id \u0026gt;= FLOOR(RAND() * max_id)）结合 LIMIT。 使用应用层随机化，而非在 SQL 层执行。 其他问题 两个日志的区别 两阶段执行过程 数据库事务 1. 介绍事务的特性 数据库事务可以保证多个对数据库的操作（也就是 SQL 语句）构成一个逻辑上的整体。简单说：要么全部执行成功,要么全部不执行 。\n具有ACID特性：\n原子性（Atomicity）：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；\n一致性（Consistency）：执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；\n隔离性（Isolation）：并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；\n持久性（Durability）：一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。\n注意：只有保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。也就是说 A、I、D 是手段，C 是目的！\n持久性是通过 redo log （重做日志）来保证的； 原子性是通过 undo log（回滚日志） 来保证的； 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的； 一致性则是通过持久性+原子性+隔离性来保证； 2. 并发事务带来的问题 脏读（Dirty read）：读取到其他事务未提交的数据。 丢失修改（Lost to modify）：指两个或多个事务同时对同一数据进行更新操作，其中一个事务的更新被另一个事务覆盖，导致前一个事务的修改丢失。 不可重复读（Unrepeatable read）：在一个事务中，前后读取的记录内容不一致； 幻读（Phantom read）：在一个事务中，前后读取的记录数量不一致。 3. 不同事务隔离级别的区别 READ-UNCOMMITTED(读取未提交) ：可以读取尚未提交的数据变更。\nREAD-COMMITTED(读取已提交) ：可以读取其他并发事务已经提交的数据。\nREPEATABLE-READ(可重复读) ：对同一字段的多次读取结果都是一致的。\nSERIALIZABLE(可串行化) ：加读写锁，保证所有的事务依次逐个执行。\n在不同隔离级别下可能发生的问题：\n隔离级别 脏读 不可重复读 幻读 读未提交 √ √ √ 读提交 × √ √ 可重复读 × × √ 串行化 × × × 4. 事务隔离的可见性实现 在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。\n在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。 在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。 “读未提交”隔离级别下直接返回记录上的最新值，没有视图概念； 而“串行化”隔离级别下直接用加锁的方式来避免并行访问。 5. 长事务的弊病 长事务意味着系统里面会存在很老的事务视图，在这个事务提交之前，回滚记录都要保留，这会导致大量占用存储空间。除此之外，长事务还占用锁资源，可能会拖垮库。\n6. MVCC是什么 MVCC 是一种并发控制机制，用于在多个并发事务同时读写数据库时保持数据的一致性和隔离性。\n读操作：当一个事务执行读操作时，它会使用快照读取。快照读取是基于事务开始时数据库中的状态创建的，因此事务不会读取其他事务尚未提交的修改。\n写操作：当一个事务执行写操作时，它会生成一个新的数据版本，事务提交后将修改后的数据写入数据库。\n为了防止数据库中的版本无限增长，MVCC 会定期进行版本的回收。回收机制会删除已经不再需要的旧版本数据，从而释放空间。\n7.MVVC中的快照是如何实现的 InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。\n数据表中的一行记录，有多个版本 (row)，每个版本有自己的 row trx_id，是transaction id进行赋值的。\n当一个事务修改表中数据的某一行时，将旧版本的数据插入 Undo Log 中，看到的视图不是物理上物理上真实存在的，而是每次需要的时候根据当前版本和 undo log 计算出来的。比如，需要 V2 视图的时候，就是通过 V4 依次执行 U3、U2 算出来。根据 row trx_id、undo log这些信息，实现了数据行的多版本效果。\n在 InnoDB 存储引擎中，创建一个新事务后，执行每个 select 语句前，都会创建一个快照（Read View），快照中保存了当前数据库系统中正处于活跃（没有 commit）的事务的 ID 号（即 m_ids）。\nRead View 存在两个变量：\nm_up_limit_id：数组里面事务 ID 的最小值 m_low_limit_id ：当前系统里面已经创建过的事务 ID 的最大值 当用户在这个事务中要读取某个记录行的时候，InnoDB 会将该记录行的 row TRX_ID 与 Read View 中的这两个变量 进行比较，判断是否满足可见性条件，不满足就回滚。\n一个数据版本的 row trx_id，有以下几种可能：\n如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的； 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的； 如果落在黄色部分，那就包括两种情况 a. 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见； b. 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。 核心简写：\n版本未提交，不可见； 版本已提交，但是是在视图创建后提交的，不可见； 版本已提交，而且是在视图创建前提交的，可见。 总结：\nrow trx_id 和 transaction id 给每个数据行提供版本号 undo log 提供版本链，帮助回滚到需要的数据 该记录行的 row TRX_ID 与 Read View 中的这两个变量 m_up_limit_id 和 m_low_limit_id 进行比较，判断是否满足可见性条件，不满足就回滚。 8. 一致性读和当前读是什么 一致性读是指事务在开启视图时候，直至提交之前，读行数据始终保持一致。主要用到MVCC（多版本并发控制） 技术，在事务中，查询语句不会看到其他事务未提交以及以后事务的更改。\n当前读是指读取行数据的最新版本，通过给行数据加Next-key Lock锁来保证的。如果当前的行数据的Next-key Lock锁被其他事务占用的话，就需要进入锁等待。在事务中执行select\u0026hellip;for update/lock in share mode、insert、update、delete 等都是当前读。\n9.幻读的定义以及幻读有什么问题？ 幻读是当一个事务在执行某个范围查询时，比如使用SELECT ... WHERE语句，第一次查询返回了一些满足条件的行，但在事务继续执行的过程中，另一个事务插入了一些新的符合查询条件的行，导致第二次相同的查询返回的结果集比第一次更多。\n关键点在于插入，导致的结果集的不同。\n其实会导致数据不一致的问题，实际上，binlog的结果和实际表不一致。一致性指的是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性。\n10.如何解决幻读 解决幻读的方式有很多，但是它们的核心思想就是一个事务在操作某张表数据的时候，另外一个事务不允许新增或者删除这张表中的数据了。\n在可重复读隔离级别，引入Next-key Lock（Record Lock+Gap Lock） 在读提交隔离级别，需要把 binlog 格式设置为 row，解决可能出现的数据和日志不一致问题， 在可重复读的事务级别下，给事务操作的这张表添加表锁。 其他问题 参考文献： https://leviathan.vip/2019/03/20/InnoDB%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%88%86%E6%9E%90-MVCC/#MVCC-1 索引 1. 哈希表、有序数组和搜索树的优缺点 哈希表是一种以键值对存储数据的结构。适用于等值查询的场景，例如NoSQL引擎，区间查询的速度很慢。 有序数组在等值查询和范围查询的场景中性能优秀，但是在更新数据上，成本太高，只适用于静态存储引擎。 搜索树的特点是父节点左子树所有结点的值小于父节点的值，右子树所有结点的值大于父节点的值。二叉树树高过高，访问多个数据块，磁盘随机读取数据块过于耗时，会采用N叉树。N取决于数据块的大小。以InnoDB 的一个整数字段索引为例，在一个节点（页）中，这个 N 差不多是 1200。 2.主键索引和普通索引是什么，在查询中的区别是什么 在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，每一个索引在 InnoDB 里面对应一棵 B+ 树。\n主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。\n非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。\n在查询过程中，基于非主键索引的查询需要回表（到主键索引树在搜索一次），相比之下多扫描一颗索引树。\n3. 主键不是有序的会带来什么问题，自增主键有什么优势，有没有什么场景适合用业务字段直接做主键的呢？ B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。当页满了，根据 B+ 树的算法，需要申请一个新的数据页，然后挪动部分数据过去，这个过程称为页分裂。页分裂操作会影响性能也会影响数据页的利用率。\n性能角度：自增主键的插入数据模式，正符合了递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。 存储空间：主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。 在场景是只有一个索引；该索引必须是唯一索引（KV场景），适合用业务字段直接做主键。\n4. 一条Sql查询语句，会扫描多少行以及几次树的搜索操作 1 2 3 4 5 6 7 8 9 10 11 12 13 # 表：主键ID索引，k索引 +-----+---+----+ | ID | k | s | +-----+---+----+ | 100 | 1 | aa | | 200 | 2 | bb | | 300 | 3 | cc | | 500 | 5 | ee | | 600 | 6 | ff | | 700 | 7 | gg | +-----+---+----+ # 执行语句： select * from T where k between 3 and 5 这条 SQL 查询语句的执行流程：\n在 k 索引树上找到 k=3 的记录，取得 ID = 300； 再到 ID 索引树查到 ID=300 对应的 R3； 在 k 索引树取下一个值 k=5，取得 ID=500； 再回到 ID 索引树查到 ID=500 对应的 R4； 在 k 索引树取下一个值 k=6，不满足条件，循环结束。 5. 说一下覆盖索引和联合索引 如果一个索引包含（或者说覆盖）所有需要查询的字段的值，（核心是无需回表查询），就称之为 覆盖索引（Covering Index） 。\n由于覆盖索引可以减少树的搜索次数，显著提升查询性能。\n使用表中的多个字段创建索引，就是 联合索引。\n6. 最左前缀原则详细介绍 最左前缀匹配原则指的是在使用索引时候，查询条件满足左前缀条件，可以利用索引加速检索。最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。\n对于一个联合索引 (A, B, C)：\n索引能被以下查询利用： WHERE A = ? WHERE A = ? AND B = ? WHERE A = ? AND B = ? AND C = ? 最左匹配原则会一直向右匹配，直到遇到范围查询（如 \u0026gt;、\u0026lt;）为止。对于 \u0026gt;=、\u0026lt;=、BETWEEN 以及前缀匹配 LIKE 的范围查询，不会停止匹配。\n7. 如何安排索引内的字段顺序 如果通过调整顺序，可以帮助少维护一个索引。\n可以将区分度高的字段放在最左边，这也可以过滤更多数据。\n考虑空间。\n8. 索引下推详细介绍 索引下推优化（index condition pushdown)是指在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数，提高查询效率。\n1 SELECT * FROM user WHERE zipcode = \u0026#39;431200\u0026#39; AND MONTH(birthdate) = 3; 9. 普通索引和唯一索引在查询和更新有什么区别 在查询过程中：\n对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。 查询带来的性能差距是微乎其微。\n在更新过程中：\n第一种情况是，这个记录要更新的目标页在内存中。\n对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束； 对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。 在该情况下，性能差别很小。\n第二种情况是，这个记录要更新的目标页不在内存中。\n对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束； 对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。 因为将数据从磁盘读入内存涉及随机 IO 的访问，是成本比较高的操作，对于唯一索引就需要不断地将数据页读入内存，然后change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。\n10. change Buffer 是什么？ 当某个行数据所在的数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了，后续会将里面操作应用在原数据页中。\n当访问这个数据页（将数据页读入内存中）会触发 merge 操作，在写多读少的业务场景中，在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），使用效果越好。但是在写入之后马上会做查询场景中，会触发change buffer的merge 过程，增加了 change buffer 的维护代价。\n11. change buffer 和 redo log 都是减少随机读写，那么之间区别是什么 redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写）（将内存的数据写入磁盘中）\nchange buffer 主要节省的则是随机读磁盘的 IO 消耗。（主要是将更新动作变缓，减少读入数据页的过程，）\n12. 当机器掉电重启，会不会导致 change buffer 丢失呢，会不会发生数据丢失情况？ 不会丢失。\nChange Buffer 的内容不仅仅在内存中也会持久化，同时Change Buffer 的修改操作（如插入、更新或删除）也会被记录到 Redo Log 中。\n在数据库掉电恢复时会重放 Redo Log，恢复未完成的事务和未刷入磁盘的修改，包括 Change Buffer 的修改。如果 Change Buffer 中有未完成的合并操作，InnoDB 会通过后台线程继续执行这些合并，将修改逐步应用到目标数据页。\n13. 前缀索引优缺点 优点：\n使用前缀索引和字段区分度有很大的关系，区分度越高越好。 前缀索引可以对字符串的前缀构建索引，定义好前缀长度，就可以做到既节省空间，又不用额外增加太多的查询成本。 缺点：\n使用前缀索引就用不上覆盖索引对查询性能的优化 前缀索引选取字段长度的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。 提高前缀索引搜索效率方式：\n对字符串字段进行处理使其区分度增加，例如倒叙、截断等； 使用hash字段； 锁 全局锁是什么，在哪些场景下使用。 全局锁就是对整个数据库实例加锁。全局锁的典型使用场景是，做全库逻辑备份。\n使用风险：\n如果在主库备份，在备份期间不能更新，业务停摆 如果在从库备份，备份期间不能执行主库同步的binlog，导致主从延迟 对于InnoDB引擎，可以通过在可重复读隔离级别下开启一个事务，获取数据，在这个过程中数据是可以正常更新的。\n官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数–single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。（只适用于支持事务引擎）\n表级别的锁有哪些？ MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。\n表锁会限制别的线程的读写外，也可能限定了本线程的读写操作，一般用的少，影响面太大了。\nMDL主要用于隔离DML（Data Manipulation Language，数据操纵语言，如select）和DDL（Data Definition Language，数据定义语言，如改表头新增一列）操作之间的干扰，保证对表数据读写正确。\n当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。\n元数据锁在什么情况下会发生阻塞？ 当有线程在执行 select 语句（ 加 MDL 读锁）的期间，如果有其他线程要更改该表的结构（ 申请 MDL 写锁），那么将会被阻塞，直到执行完 select 语句（ 释放 MDL 读锁）。\n反之，当有线程对表结构进行变更（ 加 MDL 写锁）的期间，如果有其他线程执行了 CRUD 操作（ 申请 MDL 读锁），那么就会被阻塞，直到表结构变更完成（ 释放 MDL 写锁）。\nMDL 是在事务提交后才会释放，这意味着事务执行期间，MDL 是一直持有的。\n如果长事务存在DDL操作，后面有很多DML操作发生阻塞，导致线程爆满。\n为了能安全的对表结构进行变更，在对表结构变更前，先要看看数据库中的长事务，是否有事务已经对表加上了 MDL 读锁，如果可以考虑设置超时或者 kill 掉这个长事务，然后再做表结构的变更。\n意向锁是什么，干什么用的？ 意向锁是一个表级锁，为了支持 InnoDB 的多粒度锁，它解决的是表锁和行锁共存的问题。\n意向共享锁（Intention Shared Lock，IS 锁）：事务有意向对表中的某些记录加共享锁（S 锁），加共享锁前必须先取得该表的 IS 锁。 意向排他锁（Intention Exclusive Lock，IX 锁）：事务有意向对表中的某些记录加排他锁（X 锁），加排他锁之前必须先取得该表的 IX 锁。 也就是，当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁。\n当我们需要给一个表加表锁的时候，我们需要根据去判断表中有没有数据行被锁定，以确定是否能加成功。\n假如没有意向锁，那么我们就得遍历表中所有数据行来判断有没有行锁；\n有了意向锁这个表级锁之后，则我们直接判断一次就知道表中是否有数据行被锁定了。因为意向锁会和表锁互斥。\n意向锁之间是互相兼容的。\nIS 锁 IX 锁 IS 锁 兼容 兼容 IX 锁 兼容 兼容 意向锁和共享锁和排它锁互斥（这里指的是表级别的共享锁和排他锁，意向锁不会与行级的共享锁和排他锁互斥）。\nIS 锁 IX 锁 S 锁 兼容 互斥 X 锁 互斥 互斥 行锁是什么，有哪些， 行锁就是针对数据表中行数据的锁，主要有三种：\nRecord Lock，记录锁，也就是仅仅把一条记录锁上； Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身； Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。 插入意向锁：表示了一种插入意图，即当多个不同的事务，同时往同一个索引的同一个间隙中插入数据的时候，它们互相之间无需等待，即不会阻塞。 Record Lock 称为记录锁，锁住的是一条记录。而且记录锁是有 S 锁和 X 锁之分的：\nS 锁 X 锁 S 锁 不冲突 冲突 X 锁 冲突 冲突 由于 MVCC 的存在，对于一般的 SELECT 语句，InnoDB 不会加任何锁。不过， 你可以通过以下语句显式加共享锁或排他锁。\n1 2 3 4 5 6 # 共享锁 可以在 MySQL 5.7 和 MySQL 8.0 中使用 SELECT ... LOCK IN SHARE MODE; # 共享锁 可以在 MySQL 8.0 中使用 SELECT ... FOR SHARE; # 排他锁 SELECT ... FOR UPDATE; Gap Lock：为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 。间隙锁锁住了两个值的间隙，不包括记录本身，防止进行插入操作。间隙锁之间都不存在冲突关系。\nnext-key lock：间隙锁+行锁，锁定一个范围，包含记录本身，是左开右闭的区间。\n插入意向锁：如果说间隙锁锁住的是一个区间，那么「插入意向锁」锁住的就是一个点。因而从这个角度来说，插入意向锁确实是一种特殊的间隙锁。插入意向锁和间隙锁之间是冲突的。\n两阶段协议是什么？ 两阶段锁协议：在 InnoDB 事务中，行锁是在需要（更新/插入行数据）的时候才加上的，需要等到事务结束时才释放。\n如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放，以减少锁等待的时间，提高并发性能。\nselect for update / update 等具有加锁性质的语句加锁有什么需要注意的 当我们执行 select for update / update 语句时，实际上是会对记录加锁带基本单位是 next-key 锁，加锁的位置准确的说，锁是加在索引上的而非行上。如果其他事务对持有锁的记录进行修改时是会被阻塞的。另外，这个锁并不是执行完 update 语句就会释放的，而是会等事务结束时才会释放。\n在 select for update / update 语句的查询条件没有使用索引，就会全表扫描，于是就会对所有记录加上 next-key 锁（记录锁 + 间隙锁），相当于把整个表锁住了。\n核心在于：这条语句在执行过程种，优化器最终选择的是全表扫描，那么就会对全表的记录进行加锁。\n如何避免执行加锁性质的语句锁住全表事故的发生？ 当 sql_safe_updates 设置为 1 时。update 语句必须满足如下条件之一才能执行成功：\n使用 where，并且 where 条件中必须有索引列； 使用 limit； 同时使用 where 和 limit，此时 where 条件中可以没有索引列； delete 语句必须满足以下条件能执行成功：\n同时使用 where 和 limit，此时 where 条件中可以没有索引列； 5.死锁是什么，如何解决？ 当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。\n死锁的四个必要条件：互斥、占有且等待、不可强占用、循环等待。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立。\n当出现死锁以后，有两种策略通过「打破循环等待条件」来解除：\n一种策略是，直接进入等待，直到超时。 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。 对于业务来说，第一种策略是不可取的，时间太短，会出现很多误伤，时间太长影响体验。\n正常情况下采用第二种策略，能够快速发现并进行处理的，但是它也是有额外负担的。当较多线程更新同一行，死锁检测会消耗大量的 CPU 资源。\n6.怎么解决由这种热点行更新导致的性能问题呢？ 高并发下避免死锁检测带来的负面影响：\n确保业务上不会产生死锁，直接将死锁检测关闭。（innodb 自带死锁检测） 在数据库中间件中统一对更新同一行的请求进行排队，控制并发度。 业务逻辑上进行优化，将一行数据分解成多行，降低写入压力。 9. 加锁的原则 原则 1：加锁的基本单位是 next-key lock。next-key lock 是前开后闭区间，具体执行的时候，是要分成间隙锁和行锁两段来执行的。\n原则 2：查找过程中访问到的对象才会加锁。加锁是加在索引上的。\n优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。（在唯一的，所以退化成行锁）\n优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。（因为最后一个值不满足，所以可以不加锁）\n与锁相关的：06、07、20、21、30、39、40\n内存 高可用 Mysql主备的基本流程 主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写 binlog。\n备库 B 跟主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B 的这个长连接。一个事务日志同步的完整过程是这样的：\n在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。 主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。 备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。 sql_thread 读取中转日志，解析出日志里的命令，并执行。 对于主备库为双M结构，互为主备关系，会发生什么问题？怎么解决？ 会发生循环复制的问题。\n业务逻辑在节点 A 上更新了一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog。节点 A 同时是节点 B 的备库，相当于又把节点 B 新生成的 binlog 拿过来执行了一次，然后节点 A 和 B 间，会不断地循环执行这个更新语句，也就是循环复制了。\n解决方案：\n规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系； 一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的 binlog； 每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。 主备延迟的原因 有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。 解决方案：主备库选用相同规格的机器，并且做对称部署， 备库的压力大。 解决方案：一主多从。 大事务 备库的并行复制能力。 日志篇 redolog 为什么需要 redo log redo log 是为了保证数据库的 crash-safe 能力。 当数据库发生异常（如宕机或掉电）时，redo log 能够帮助恢复已提交但尚未完全持久化到数据文件的事务，确保数据一致性并减少数据丢失。\n什么是 redo log redo log 是 InnoDB 存储引擎实现的物理日志，用于记录对数据页的修改操作。它的关键特性包括：\n记录内容： 记录某个表空间中某数据页特定位置的修改，例如对表空间 XXX 中数据页 YYY 偏移量 ZZZ 的更新 AAA。\n固定大小，循环写入： 默认大小为 4 GB，由多个日志文件组成，循环写入。\nwrite pos（写指针）：记录当前写入的位置，随着写入不断推进，循环至日志文件的开头。 checkpoint（检查点指针）：记录当前可以被擦除的位置。在擦除之前，日志内容必须已应用到数据文件中。 优点：\n实现事务的持久性，让 MySQL 有 crash-safe 的能力，能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失； 将写操作从「随机写」变成了「顺序写」，提升 MySQL 写入磁盘的性能。 binlog 是server层实现，是逻辑日志，记录的是语句的原始逻辑。比如“给 ID=2 这一行的 c 字段加 1 ”\n是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n主要用于备份恢复，主从恢复，增量备份。\n数据恢复：在数据库发生故障时，通过 binlog 可以进行数据的恢复。 主从复制：在主从架构中，binlog 用于同步主库的操作到从库。 增量备份：binlog 支持记录数据库的增量变化，便于在全量备份的基础上快速恢复最新数据。 undolog undo log 是一种用于撤销回退的日志。在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。【可以理解成一种版本链】\n它保证了事务的 ACID 特性 (opens new window)中的原子性（Atomicity）。\n在发生回滚时，就读取 undo log 里的数据，然后做原先相反操作。比如当 delete 一条记录时，undo log 中会把记录中的内容都记下来，然后执行回滚操作的时候，就读取 undo log 里的数据，然后进行 insert 操作。\n针对 delete 操作和 update 操作会有一些特殊的处理：\ndelete操作实际上不会立即直接删除，而是将delete对象打上delete flag，标记为删除，最终的删除操作是purge线程完成的。 update分为两种情况：update的列是否是主键列。 如果不是主键列，在undo log中直接反向记录是如何update的。即update是直接进行的。 如果是主键列，update分两部执行：先删除该行，再插入一行目标行。 undo log 还有一个作用，通过 ReadView + undo log 实现 MVCC（多版本并发控制）。\n对于「读提交」和「可重复读」隔离级别的事务来说，它们的快照读（普通 select 语句）是通过「事务的 Read View 里的字段」和「记录中的两个隐藏列（trx_id 和 roll_pointer）」的比对，如果不满足可见行，就会顺着 undo log 版本链里找到满足其可见性的记录。\n因此，undo log 两大作用：\n实现事务回滚，保障事务的原子性。事务处理过程中，如果出现了错误或者用户执 行了 ROLLBACK 语句，MySQL 可以利用 undo log 中的历史数据将数据恢复到事务开始之前的状态。 实现 MVCC（多版本并发控制）关键因素之一。MVCC 是通过 ReadView + undo log 实现的。undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录。 两阶段提交日志具体流程 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。 为什么是两阶段提交日志 核心目的：保证两份日志之间的逻辑一致（数据一致性）。\n从反证法说明：\n先写 redo log 直接提交，然后写 binlog：假设写完 redo log 后，机器挂了，binlog 日志没有被写入，那么机器重启后，这台机器会通过 redo log 恢复数据，但是这个时候 binlog 并没有记录该数据，后续进行机器备份的时候，就会丢失这一条数据，同时主从同步也会丢失这一条数据。\n先写 binlog，然后写 redo log，假设写完了 binlog，机器异常重启了，由于没有 redo log，本机是无法恢复这一条记录的，但是 binlog 又有记录，那么和上面同样的道理，就会产生数据不一致的情况。\n两阶段提交日志存在什么问题？ 两阶段提交虽然保证了两个日志文件的数据一致性，但是性能很差，主要有两个方面的影响：\n磁盘 I/O 次数高：对于“双1”配置，每个事务提交都会进行两次 fsync（刷盘），一次是 redo log 刷盘，另一次是 binlog 刷盘。 锁竞争激烈：两阶段提交虽然能够保证「单事务」两个日志的内容一致，但在「多事务」的情况下，却不能保证两者的提交顺序一致，因此，在两阶段提交的流程基础上，还需要加一个锁来保证提交的原子性，从而保证多事务的情况下，两个日志的提交顺序一致。 什么时候，怎么刷盘binlog 写入的机制：事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。\n一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。系统给 binlog cache 分配了一片内存，每个线程一个，如果超过了参数规定的大小，就要暂存到磁盘的page cache。\n对于持久化也涉及到两步：\nwrite，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘。 fsync，才是将数据持久化到磁盘的操作。 MySQL提供一个 sync_binlog 参数来控制数据库的 binlog 刷到磁盘上的频率：\nsync_binlog = 0 的时候，表示每次提交事务都只 write，不 fsync，后续交由操作系统决定何时将数据持久化到磁盘； sync_binlog = 1 的时候，表示每次提交事务都会 write，然后马上执行 fsync； sync_binlog =N(N\u0026gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。 不同的设置会带来不同的结果：\n设置是 sync_binlog = 0，这时候的性能是最好的，但是风险也是最大的。因为一旦主机发生异常重启，还没持久化到磁盘的数据就会丢失。\nsync_binlog 设置为 1 的时候，是最安全但是性能损耗最大的设置。因为当设置为 1 的时候，即使主机发生异常重启，最多丢失一个事务的 binlog，而已经持久化到磁盘的数据就不会有影响，不过就是对写入性能影响太大。\nsync_binlog 设置为 N的时候，需要能容少量事务的 binlog 日志丢失的风险。\n什么时候，怎么刷盘redo log 执行一个事务的过程中，产生的 redo log 也不是直接写入磁盘的，会先写入到 redo log buffer，后续在持久化到磁盘。\n为了控制 redo log 的写入策略，InnoDB 提供了 innodb_flush_log_at_trx_commit 参数，它有三种可能取值：\n当设置该参数为 0 时，表示每次事务提交时 ，还是将 redo log 留在 redo log buffer 中 ，该模式下在事务提交时不会主动触发写入磁盘的操作。 当设置该参数为 1 时，表示每次事务提交时，都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘，这样可以保证 MySQL 异常重启之后数据不会丢失。 当设置该参数为 2 时，表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log 写到文件的page cache。 InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。\n如果 write pos 追上了 checkpoint，就意味着 redo log 文件满了，这时 MySQL 不能再执行新的更新操作，也就是说 MySQL 会被阻塞（因此所以针对并发量大的系统，适当设置 redo log 的文件大小非常重要），此时会停下来将 Buffer Pool 中的脏页刷新到磁盘中，然后标记 redo log 哪些记录可以被擦除，接着对旧的 redo log 记录进行擦除，等擦除完旧记录腾出了空间，checkpoint 就会往后移动（图中顺时针），然后 MySQL 恢复正常运行，继续执行新的更新操作。\nbinlog的三种格式之间的对比。 binlog 有三种格式，一种是 statement，一种是 row，第三种格式 mixed，是前两种格式的混合。\nstatement 格式中 binlog文件记录的是真实执行的语句。存在主备不一致的情况，例如在主库执行这条 SQL 语句的时候，用的是索引 a；而在备库执行这条 SQL 语句的时候，却使用了索引 b。\nrow 格式的binlog记录的是真实数据行的字段的值，不存在主备不一致。\n前两种格式各自的优缺点：\n因为 statement 格式的 binlog 可能会导致主备不一致，row 格式不会发生这个问题。 但 row 格式的缺点是，很占空间。比如你用一个 delete 语句删掉 10 万行数据，用 statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。这样做，不仅会占用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度。 所以根据这些优缺点，MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。\n在两阶段提交日志，有什么方法可以降低磁盘IO？ 依赖于组提交（group commit）机制。\n日志逻辑序列号（log sequence number，LSN） 是单调递增的，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redo log， LSN 的值就会加上 length。\n有三组并发事务都要持久化磁盘，LSN都不一样，对应的 LSN 分别是 50、120 和 160。。过程如下：\ntrx1 是第一个到达的，会被选为这组的 leader； 等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN 也变成了 160； trx1 去写盘的时候，带的就是 LSN=160，因此等 trx1 返回时，所有 LSN 小于等于 160 的 redo log，都已经被持久化到磁盘； 这时候 trx2 和 trx3 就可以直接返回了。 一次组提交里面，组员越多，节约磁盘 IOPS 的效果越好。\n引入了组提交机制后，两阶段提交日志中的 prepare 阶段不变，对于binlog的wirte 阶段拆分为三个过程：\nflush 阶段：多个事务按进入的顺序将 binlog 从 cache 写入文件（不刷盘）； sync 阶段：对 binlog 文件做 fsync 操作（多个事务的 binlog 合并一次刷盘）； 上面的每个阶段都有一个队列，每个阶段有锁进行保护，因此保证了事务写入的顺序，第一个进入队列的事务会成为 leader，leader领导所在队列的所有事务，全权负责整队的操作，完成后通知队内其他事务操作结束。\n为了提高redolog组提交性能，在 prepare 阶段不再让事务各自执行 redo log 刷盘操作，而是推迟到组提交的 flush 阶段之后。（在两个阶段之间）通过延迟写 redo log 的方式，为 redolog 做了一次组写入。\n如果想提升 binlog 组提交的效果，可以通过设置下面这两个参数来实现：\nbinlog_group_commit_sync_delay= N，表示在等待 N 微妙后，直接调用 fsync，将处于文件系统中 page cache 中的 binlog 刷盘，也就是将「 binlog 文件」持久化到磁盘。 binlog_group_commit_sync_no_delay_count = N，表示如果队列中的事务数达到 N 个，就忽视binlog_group_commit_sync_delay 的设置，直接调用 fsync，将处于文件系统中 page cache 中的 binlog 刷盘。 如果你的 MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？ 设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。 将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。 场景题 1. 在什么情况下会出现查一行数据会执行得特别慢的现象？ 等锁\n等表级锁，例如MDL写锁 等flush表 等行锁 查询慢\n没有走索引，全表扫描 回滚日志过大引起的一致性读慢 2. 业务高峰期，生产环境的 MySQL 压力太大，没法正常响应，有哪些方案可以短期内、临时性地提升一些性能。 第一种情况：短连接风暴\n当处于业务高峰期时候，MySQL 建立连接的过程，除了正常的网络连接三次握手外，还需要做登录权限判断和获得这个连接的数据读写权限，成本较高\n解决方案：\n第一种方法：先处理掉那些占着连接但是不工作的线程。 可以设置wait_timeout参数，将一个线程空闲 wait_timeout 这么多秒之后，就会被 MySQL 直接断开连接。 优先断开事务外的连接 第二种方法：减少连接过程的消耗。让数据库跳过权限验证阶段。 第二种情况：慢查询引起的性能问题\n存在三种可能\n索引没有设计好； 解决方案：在主从库上紧急添加索引 SQL 语句没写好；（可能没有用索引等） 解决方案：query_rewrite 功能，可以把输入的一种语句改写成另外一种模式。 MySQL 选错了索引。 解决方案：使用查询重写功能，给原来的语句加上 force index， 第三种情况：QPS 突增问题\n采用虚拟化、白名单机制、业务账号分离等方法，然后相关服务停掉。\n3. 全表扫描，server层的流程 获取一行，写到 net_buffer 中。这块内存的大小是由参数 net_buffer_length 定义的，默认是 16k。 重复获取行，直到 net_buffer 写满，调用网络接口发出去。 如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。 如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送。 ","date":"2024-11-30T00:00:00Z","permalink":"https://www.yangdiy.cn/p/mysql/","title":"Mysql-八股题"}]